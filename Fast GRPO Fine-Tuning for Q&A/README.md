
---

## **Fast GRPO Fine-Tuning for Q&A: How We Outperformed OpenAI’s O1-Preview with Qwen-0.5B in 50 Minutes**

```markdown
# Discover how GRPO fine-tuning and LLM-Judge (LLM-J) helped Qwen-0.5B surpass OpenAI’s O1-preview in Q&A—optimized in just 50 minutes on Colab A100!

This directory contains the code and resources for the blog post:

**"Fast GRPO Fine-Tuning for Q&A: How We Outperformed OpenAI’s O1-Preview with Qwen-0.5B in 50 Minutes"**

## Contents

- `Qwen_Grpo_Training.ipynb`: Jupyter notebook for fine-tuning the QWEN model.
- `Taylor_Swift_o1_preview_evaluation.ipynb`: Jupyter notebook for evaluating o1-preview model on this task.
- `README.md`: Instructions and details for this blog.

## Getting Started

### Prerequisites

- Python 3.7 or higher
- Access to a GPU (e.g., NVIDIA A100) is recommended for fine-tuning.

### Installation

1. **Create a virtual environment** (optional but recommended):

   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
